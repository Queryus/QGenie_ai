# src/core/providers/llm_provider.py

import os
import asyncio
import logging
from typing import Optional
from langchain_openai import ChatOpenAI
from core.clients.api_client import get_api_client

logger = logging.getLogger(__name__)

class LLMProvider:
    """
    LLM ì œê³µìë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    ì§€ì—° ì´ˆê¸°í™”ë¥¼ ì§€ì›í•˜ì—¬ BE ì„œë²„ê°€ ëŠ¦ê²Œ ì‹œì‘ë˜ì–´ë„ ì‘ë™í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, model_name: str = "gpt-4o-mini", temperature: float = 0):
        self.model_name = model_name
        self.temperature = temperature
        self._llm: Optional[ChatOpenAI] = None
        self._api_key: Optional[str] = None
        self._api_client = None
        self._initialization_attempted: bool = False
        self._initialization_failed: bool = False
    
    async def _load_api_key(self) -> str:
        """ë°±ì—”ë“œì—ì„œ OpenAI API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            if self._api_key is None:
                if self._api_client is None:
                    self._api_client = await get_api_client()
                
                self._api_key = await self._api_client.get_openai_api_key()
                return self._api_key
            
        except Exception as e:
            logger.error(f"Failed to fetch API key from backend: {e}")
            raise ValueError("ë°±ì—”ë“œì—ì„œ OpenAI API í‚¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    async def get_llm(self) -> ChatOpenAI:
        """
        ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ì§€ì—° ì´ˆê¸°í™”ë¥¼ í†µí•´ BE ì„œë²„ ì—°ê²°ì´ ì‹¤íŒ¨í•´ë„ ì¬ì‹œë„í•©ë‹ˆë‹¤.
        """
        if self._llm is None:
            # ì´ì „ì— ì´ˆê¸°í™”ë¥¼ ì‹œë„í–ˆê³  ì‹¤íŒ¨í–ˆë‹¤ë©´ ì¬ì‹œë„
            if self._initialization_failed:
                logger.info("ğŸ”„ LLM ì´ˆê¸°í™” ì¬ì‹œë„ ì¤‘...")
                self._initialization_failed = False
                self._initialization_attempted = False
            
            try:
                self._initialization_attempted = True
                self._llm = await self._create_llm()
                self._initialization_failed = False
                logger.info("âœ… LLM ì´ˆê¸°í™” ì„±ê³µ")
                
            except Exception as e:
                self._initialization_failed = True
                logger.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"LLMì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")

        return self._llm
    
    async def _create_llm(self) -> ChatOpenAI:
        """ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # API í‚¤ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ë¡œë“œ
            api_key = await self._load_api_key()
            logger.info("âœ… ë°±ì—”ë“œì—ì„œ OpenAI API í‚¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤")
            
            llm = ChatOpenAI(
                model=self.model_name,
                temperature=self.temperature,
                api_key=api_key
            )
            return llm
            
        except Exception as e:
            raise RuntimeError(f"LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def update_model(self, model_name: str, temperature: float = None):
        """ëª¨ë¸ ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•˜ê³  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤."""
        self.model_name = model_name
        if temperature is not None:
            self.temperature = temperature
        self._llm = None  # ë‹¤ìŒ í˜¸ì¶œ ì‹œ ì¬ìƒì„±ë˜ë„ë¡ í•¨
    
    async def refresh_api_key(self):
        """API í‚¤ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤."""
        self._api_key = None
        self._llm = None  # LLM ì¸ìŠ¤í„´ìŠ¤ë„ ì¬ìƒì„±
        self._initialization_attempted = False
        self._initialization_failed = False
        logger.info("API key refreshed")
    
    async def test_connection(self) -> bool:
        """LLM ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
        try:
            llm = await self.get_llm()
            test_response = await llm.ainvoke("í…ŒìŠ¤íŠ¸")
            return test_response is not None
            
        except Exception as e:
            print(f"LLM ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_llm_provider = LLMProvider()

async def get_llm_provider() -> LLMProvider:
    """LLM Provider ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return _llm_provider
